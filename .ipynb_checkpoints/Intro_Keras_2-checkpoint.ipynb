{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa71124b",
   "metadata": {},
   "source": [
    "Steps in modelling with Tensorflow:\n",
    "\n",
    "0. Get training data ready (turn into tensors)\n",
    "1. Create a model (or pick a pretrained model): define the input, output layers, and the hidden layers of a DL model;\n",
    "2. Compile a model - define the loss function, the optimizer, and the evaluation metrics;\n",
    "3. Fit a model (Evaluate the model) - letting the model try to find patterns between features and labels;\n",
    "4. Improve the model through experimentation (Hyperparameter tuning);\n",
    "5. Visualize, interpret the result and save your trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db820f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices('GPU') \n",
    "# for device in physical_devices:\n",
    "#     tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd67d31",
   "metadata": {},
   "source": [
    "### The three dataset\n",
    "* Training dataset - the model learns from this data, typically around 70% \n",
    "* Validation dataset - the models gets tuned on this data, typically around 15%\n",
    "* Test dataset - the model get evaluted on this data, typically around 15%`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 0. Create data\n",
    "X = np.arange(0, 100, 1, dtype='float64')\n",
    "noise = 10*np.random.rand(100) \n",
    "Y = 2*X + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50940d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X, Y) \n",
    "plt.rcParams['figure.figsize'] = [3, 2]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60682df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_rem, Y_train, Y_rem = train_test_split(X, Y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4845da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_rem.shape, Y_rem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbe7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_test, Y_valid, Y_test = train_test_split(X_rem, Y_rem, test_size=0.5, random_sate=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.shape, Y_valid.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad7e62",
   "metadata": {},
   "source": [
    "create a model which builds automatically by defining the input_shape argument in the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa04f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model using the Sequential API (Old version in Intro_Keras_1)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae, \n",
    "             optimizer = tf.keras.optimizers.Adam(lr=0.1),  \n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=[1], name='input_layer')\n",
    "    #,tf.keras.layers.Dense(1, name='output_layer')\n",
    "], name='A_simple_MLP_model_for_the_HAL_workshop')\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.losses.mse, \n",
    "             optimizer = tf.keras.optimizers.Adam(lr=0.01),  \n",
    "             metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7146de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Fit the model\n",
    "model.fit(X_train,Y_train, epochs=400) #verbose=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8437669",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(X_train, Y_train, c=\"b\", label = \"Training data\")\n",
    "plt.scatter(X_test, Y_test, c=\"g\", label = \"Training data\")\n",
    "plt.scatter(X_test, Y_pred, c=\"r\", label = \"Training data\")\n",
    "plt.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25633cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate some metrics to evaluate the model performance\n",
    "mae = tf.metrics.mean_absolute_error(Y_test, tf.squeeze(Y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8880639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate some metrics to evaluate the model performance\n",
    "mse = tf.metrics.mean_squared_error(Y_test, tf.squeeze(Y_pred))\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize and save the model that you just trained \n",
    "saved_model_path = \"./saved_model/my_model\" # or saved using the HDF5 format \"./saved_model/my_model.h5\" \n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2585dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -al ./saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139183cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a pretrained model that you just saved\n",
    "loaded_model = tf.keras.models.load_model(\"./saved_model/my_model\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wmlce-v1.7.0]",
   "language": "python",
   "name": "conda-env-wmlce-v1.7.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
