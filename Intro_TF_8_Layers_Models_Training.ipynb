{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68765efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631884a",
   "metadata": {},
   "source": [
    "## 1. Defining Custom Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f911e83",
   "metadata": {},
   "source": [
    "The fundamental data structure in neural networks is the layer. A Layer is an object that encapsulates some state (weights) and some computation (a forward pass). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40400671",
   "metadata": {},
   "source": [
    "`tf.keras.layers.Layer` is the base class of all Keras layers, and it inherits from `tf.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ee931",
   "metadata": {},
   "source": [
    "#### a)  Define a Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2393cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    # Adding **kwargs to support base Keras layer arguments\n",
    "    def __init__(self, in_features, out_features, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.w = tf.Variable(\n",
    "          tf.random.normal([in_features, out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
    "    \n",
    "    def call(self, x):\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        return tf.nn.relu(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f51326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 14:21:58.961322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13868 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.7962775e-01 0.0000000e+00 2.3954311e-01 0.0000000e+00]\n",
      " [2.8620921e-03 5.4509607e-03 6.0050189e-04 1.7908085e-02]\n",
      " [1.5226889e+00 0.0000000e+00 1.7441623e+00 0.0000000e+00]\n",
      " [2.0285544e-01 0.0000000e+00 2.1732186e-01 7.7112041e-02]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your layer\n",
    "\n",
    "simple_layer = MyDense(name=\"simple\", in_features=2, out_features=4)\n",
    "\n",
    "\n",
    "# Call the layer on a sample input\n",
    "\n",
    "x = tf.random.normal((4,2))\n",
    "y = simple_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc483d54",
   "metadata": {},
   "source": [
    "#### b) Build Method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a64c5",
   "metadata": {},
   "source": [
    "It is often convenient to delay creating variables until the input shape is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac961342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([self.units]), name='b')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f73dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.57103574  0.7056963   0.7831032  -0.19645812]\n",
      " [ 0.48449224  0.81514645 -1.4123813  -0.1140079 ]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your layer\n",
    "\n",
    "flexible_layer = MyDense(name=\"simple\", units=4)\n",
    "\n",
    "# Call the layer on a sample input\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "y = flexible_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d806f781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple/w:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[-0.45592713, -0.8679294 ,  2.2968946 ,  0.08273923],\n",
       "        [-0.6029403 , -0.79532725, -0.3450636 ,  0.19521433]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple/b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this point we can inspect the variable\n",
    "\n",
    "flexible_layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11081e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple/b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also call the variables by name\n",
    "\n",
    "flexible_layer.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2ab5c",
   "metadata": {},
   "source": [
    "#### c) Non-trainable weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818c5d9",
   "metadata": {},
   "source": [
    "By default, the variables in a layer are trainable, i.e. they will tracked by the Gradient Tape and will be updated during backpropagation. However, we can also specify certain weights to be non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27f0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]), name='w', trainable=True)\n",
    "        self.b = tf.Variable(tf.zeros([self.units]), name='b', trainable=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6682423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the layer\n",
    "\n",
    "my_new_layer = MyDense(units=16)\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "y = my_new_layer(x)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ad08cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 2\n",
      "non-trainable weights: 1\n",
      "\n",
      " trainable_weights: [<tf.Variable 'my_dense/w:0' shape=(2, 16) dtype=float32, numpy=\n",
      "array([[-0.92421454,  1.5271708 , -0.4960448 ,  1.5989587 , -1.3676745 ,\n",
      "        -1.1980149 , -1.2600694 , -1.4967078 , -2.151099  , -0.46432722,\n",
      "        -0.7747701 ,  0.7667752 ,  0.04655676,  1.0415165 , -0.46837953,\n",
      "        -0.2175416 ],\n",
      "       [ 0.5059733 ,  0.07195085,  1.3277142 ,  0.39718327, -0.47133386,\n",
      "        -0.69949687,  0.22331789, -0.71972126, -0.61923885, -0.41485408,\n",
      "        -1.4939994 ,  0.5567221 ,  2.3393505 ,  0.4795249 ,  1.1922231 ,\n",
      "        -2.4104273 ]], dtype=float32)>]\n",
      "\n",
      " non trainable_weights: [<tf.Variable 'my_dense/b:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(\"weights:\", len(my_new_layer.weights))\n",
    "print(\"non-trainable weights:\", len(my_new_layer.non_trainable_weights))\n",
    "\n",
    "\n",
    "# It's not included in the trainable weights:\n",
    "print(\"\\n trainable_weights:\", my_new_layer.trainable_weights)\n",
    "print(\"\\n non trainable_weights:\", my_new_layer.non_trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8aeef",
   "metadata": {},
   "source": [
    "#### d) training arg in call()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "105bf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropout(tf.keras.layers.Layer):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(CustomDropout, self).__init__(**kwargs)\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate=self.rate)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e01b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tf.Tensor(\n",
      "[[ 0.6040804   0.37629202]\n",
      " [ 1.1000711  -1.6269804 ]], shape=(2, 2), dtype=float32)\n",
      "\n",
      " output_during_training:  tf.Tensor(\n",
      "[[ 1.2081608  0.       ]\n",
      " [ 2.2001421 -0.       ]], shape=(2, 2), dtype=float32)\n",
      "\n",
      " output_during_inference:  tf.Tensor(\n",
      "[[ 0.6040804   0.37629202]\n",
      " [ 1.1000711  -1.6269804 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dropuout = CustomDropout(rate=0.5)\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "print('input: ', x)\n",
    "\n",
    "\n",
    "# During training\n",
    "output_during_training = dropuout(x, training=True)\n",
    "print('\\n output_during_training: ', output_during_training)\n",
    "\n",
    "\n",
    "# During inference\n",
    "output_during_inference = dropuout(x, training=False)\n",
    "print('\\n output_during_inference: ', output_during_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad32be",
   "metadata": {},
   "source": [
    "#### e) Recursively composible  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef3770",
   "metadata": {},
   "source": [
    "It also possible to compose a layer out of other layers. The outer layer will automatically track the weights of the inner layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3430e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 6\n",
      "trainable weights: 3\n",
      "y.shape:  (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Let's assume we are reusing the Linear class\n",
    "# with a `build` method that we defined above.\n",
    "\n",
    "\n",
    "class MLPBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.dense_1 = MyDense(32)\n",
    "        self.dense_2 = MyDense(32)\n",
    "        self.dense_3 = MyDense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return self.dense_3(x)\n",
    "\n",
    "\n",
    "mlp = MLPBlock()\n",
    "y = mlp(tf.ones(shape=(3, 64)))  # The first call to the `mlp` will create the weights\n",
    "print(\"weights:\", len(mlp.weights))\n",
    "print(\"trainable weights:\", len(mlp.trainable_weights))\n",
    "print(\"y.shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a134696",
   "metadata": {},
   "source": [
    "## 2. Defining Models: Three Levels of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb898c",
   "metadata": {},
   "source": [
    "Given a set of (either predefined or custom defined) layers, we can begin to start composing them into a DAG to define a model. A `tf.keras.Model` is similar to a `tf.keras.layers.Layer` except that models come with extra functionality that make them easy to train, evaluate, load, save, and even train on multiple machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e6f1f",
   "metadata": {},
   "source": [
    "#### a) Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b20252",
   "metadata": {},
   "source": [
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90892fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two ways to define a sequential model:\n",
    "\n",
    "# 1. Either as a list of layers\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(input_shape=(4,)),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(16),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Or instantiate a Sequential Model and add layers by calling the .add() method on it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.Dense(16))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "189310ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Now we can call the model on an Input Tensor\n",
    "x = tf.ones((16, 4))\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee53f0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 32)                160       \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can call summary method to display the graph\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609806d",
   "metadata": {},
   "source": [
    "#### b) Functional API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e28fe3",
   "metadata": {},
   "source": [
    "The __Functional API__ is more flexible than Sequential, and specifically come in handy when the model has non-linear topology, shared layers and/or multiple inputs, outputs.\n",
    "\n",
    "First, lets redefine the above model in Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a77a9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(4,))\n",
    "\n",
    "x = tf.keras.layers.Dense(32)(inputs)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Dense(16)(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"functional_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62392e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                160       \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 16)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f740b",
   "metadata": {},
   "source": [
    "With Functional API, it's easy to define more complex topologies. Lets define a model with multiple inputs and outputs.\n",
    "\n",
    "Let's say we want a model that takes in a few weather data variables on any given day to predict temperature and humidity for the same day:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "- Pressure\n",
    "- Precipitation\n",
    "- Clouds\n",
    "- Wind\n",
    "\n",
    "\n",
    "Outputs:\n",
    "\n",
    "- Temperature\n",
    "- Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd907233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets build this model\n",
    "\n",
    "pressure_input = tf.keras.layers.Input(shape=(1,), name='pressure')\n",
    "precipitation_input = tf.keras.layers.Input(shape=(1,), name='precipitation')\n",
    "clouds_input = tf.keras.layers.Input(shape=(1,), name='clouds')\n",
    "wind_input = tf.keras.layers.Input(shape=(1,), name='wind')\n",
    "\n",
    "\n",
    "# Lets pass the pressure and precipitaion through a one stack of linear layers, and clouds and wind through another\n",
    "x = tf.keras.layers.concatenate([pressure_input, precipitation_input])\n",
    "x = tf.keras.layers.Dense(units=32, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=16, activation='relu')(x)\n",
    "\n",
    "\n",
    "y = tf.keras.layers.concatenate([clouds_input, wind_input])\n",
    "y = tf.keras.layers.Dense(units=32, activation='relu')(y)\n",
    "y = tf.keras.layers.Dense(units=16, activation='relu')(y)\n",
    "\n",
    "\n",
    "# Lets merge the two branches and send through a few more layers\n",
    "z = tf.keras.layers.concatenate([x,y])\n",
    "z = tf.keras.layers.Dense(units=32, activation='relu')(z)\n",
    "z = tf.keras.layers.Dense(units=16, activation='relu')(z)\n",
    "\n",
    "# Finally split again into two outputs\n",
    "temperature = tf.keras.layers.Dense(units=1, name='temperature')(z)\n",
    "humidity = tf.keras.layers.Dense(units=1, name='humidity')(z)\n",
    "\n",
    "\n",
    "multiple_inp_model = tf.keras.Model(inputs=[pressure_input, precipitation_input, clouds_input, wind_input], \n",
    "                       outputs=[temperature, humidity], name=\"multi_input_output_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eeaa794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi_input_output_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " pressure (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " precipitation (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " clouds (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " wind (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2)            0           ['pressure[0][0]',               \n",
      "                                                                  'precipitation[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2)            0           ['clouds[0][0]',                 \n",
      "                                                                  'wind[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 32)           96          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 32)           96          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 16)           528         ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 16)           528         ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32)           0           ['dense_10[0][0]',               \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 32)           1056        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 16)           528         ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " temperature (Dense)            (None, 1)            17          ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " humidity (Dense)               (None, 1)            17          ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,866\n",
      "Trainable params: 2,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can print the summary but it might be difficult to visualize the graph\n",
    "multiple_inp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deb92d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# Luckily we can also plot the model\n",
    "tf.keras.utils.plot_model(multiple_inp_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d1a9b",
   "metadata": {},
   "source": [
    "#### c) Subclassing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c91f948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FCN, self).__init__()\n",
    "        self.dense_1 = tf.keras.layers.Dense(32)\n",
    "        self.dense_2 = tf.keras.layers.Dense(16)\n",
    "        self.dense_3 = tf.keras.layers.Dense(1)\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.dense_3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f460f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "model = FCN()\n",
    "\n",
    "\n",
    "# Call the model on an Input Tensor\n",
    "x = tf.ones((16, 4))\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcd8cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fcn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            multiple                  160       \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  528       \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  17        \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d251e92",
   "metadata": {},
   "source": [
    "## 3. Training: Three Levels of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59662669",
   "metadata": {},
   "source": [
    "For this exercise, we will fix the model architecture (a small CNN) and train it on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3068e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "train_images, val_images = train_images[:50000], train_images[50000:]\n",
    "train_labels, val_labels = train_labels[:50000], train_labels[50000:]\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "val_labels = to_categorical(val_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b01d2911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "Input = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(Input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "Output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "my_CNN = tf.keras.Model(inputs=Input, outputs=Output)\n",
    "my_CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04d592",
   "metadata": {},
   "source": [
    "#### a) Model.fit() method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4528e",
   "metadata": {},
   "source": [
    "To use the built in methods `(Model.fit(), Model.evaluate(), Model.predict() `, we simply need to specify the\n",
    "- optimizer\n",
    "- loss\n",
    "- metrics\n",
    "\n",
    "and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56b655a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_CNN.compile(\n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    # Loss function to minimize\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a0938",
   "metadata": {},
   "source": [
    "The `.fit()` method will accept `numpy arrays`, `tf.data.Dataset` objects and `data generators`. Here we will input the MNIST data as a numpy array.\n",
    "\n",
    "The `.fit()` method can slice the data into batches, and will iterate over the entire dataset for a given number of epochs. Additionally, after each epoch it will evaluate on a hold-out validation set if specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f91d4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 14:22:02.926944: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 8s 5ms/step - loss: 0.2008 - categorical_accuracy: 0.9379 - val_loss: 0.0709 - val_categorical_accuracy: 0.9790\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0534 - categorical_accuracy: 0.9836 - val_loss: 0.0527 - val_categorical_accuracy: 0.9842\n"
     ]
    }
   ],
   "source": [
    "history = my_CNN.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    validation_data=(val_images, val_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd1e6b",
   "metadata": {},
   "source": [
    "The returned history object holds a record of the loss and metric values recorded at the end of each epoch during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ed3a4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.20084823668003082, 0.053356219083070755],\n",
       " 'categorical_accuracy': [0.9378600120544434, 0.9836000204086304],\n",
       " 'val_loss': [0.0709243193268776, 0.0527166984975338],\n",
       " 'val_categorical_accuracy': [0.9789999723434448, 0.9842000007629395]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7bac2",
   "metadata": {},
   "source": [
    "After training, we can call the `evaaluate` or `predict` methods on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b0c4559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0390 - categorical_accuracy: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.038979899138212204, 0.9872000217437744]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_CNN.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dce7c1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = my_CNN.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "324636e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa68b6e",
   "metadata": {},
   "source": [
    "###### What if there are multiple outputs? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2529838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple_inp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edd13da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_inp_model.compile(\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    \n",
    "    # Loss function to minimize\n",
    "    loss = {\n",
    "        'temperature': tf.keras.losses.MeanSquaredError(),\n",
    "        'humidity': tf.keras.losses.CategoricalCrossentropy()\n",
    "    },\n",
    "    \n",
    "    # List of metrics to monitor\n",
    "    metrics = {\n",
    "        'temperature': [tf.keras.metrics.MeanAbsoluteError(),],\n",
    "        'humidity': [tf.keras.metrics.CategoricalAccuracy(),]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07378b",
   "metadata": {},
   "source": [
    "#### b) Customizing what happens in Model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a8101",
   "metadata": {},
   "source": [
    "To customize what `fit()` does, we just need to override the `train_step(self, data)` method of the `Model` class.\n",
    "\n",
    "Let's do this with our simple CNN from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9159f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
    "\n",
    "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "accuracy_tracker = tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "\n",
    "\n",
    "class CustomModel(tf.keras.Model):\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute our own loss\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, y_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Compute our own metrics\n",
    "        loss_tracker.update_state(loss)\n",
    "        accuracy_tracker.update_state(y, y_pred)\n",
    "        return {\"loss\": loss_tracker.result(), \"acc\": accuracy_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [loss_tracker, accuracy_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bd77ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the architecture\n",
    "Input = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(Input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "Output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reconstruct an instance of our CNN model\n",
    "my_new_CNN = CustomModel(inputs=Input, outputs=Output)\n",
    "\n",
    "# Now during compilation we don't need to pass loss or metrics\n",
    "my_new_CNN.compile(optimizer=\"adam\")\n",
    "\n",
    "# Print summary\n",
    "my_new_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a871b5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.2101 - acc: 0.8513\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0546 - acc: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffef0437820>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train \n",
    "my_new_CNN.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size=64,\n",
    "    epochs=2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996535a0",
   "metadata": {},
   "source": [
    "#### c) Training Loop from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aeff190d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "\n",
    "Input = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(Input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "Output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=Input, outputs=Output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1be387ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to simulate batches\n",
    "\n",
    "batch_size= 16\n",
    "\n",
    "train_images = train_images.reshape(-1, batch_size, 28,28,1)\n",
    "val_images = val_images.reshape(-1, batch_size, 28,28,1)\n",
    "test_images = test_images.reshape(-1, batch_size, 28,28,1)\n",
    "\n",
    "train_labels = train_labels.reshape(-1, batch_size, 10)\n",
    "val_labels = val_labels.reshape(-1, batch_size, 10)\n",
    "test_labels = test_labels.reshape(-1, batch_size, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e92019d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer, Loss functions and Metrics\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "# Prepare the metrics.\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81c15833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 2.2869\n",
      "Seen so far: 16 samples\n",
      "Training loss (for one batch) at step 200: 0.3065\n",
      "Seen so far: 3216 samples\n",
      "Training loss (for one batch) at step 400: 0.0443\n",
      "Seen so far: 6416 samples\n",
      "Training loss (for one batch) at step 600: 0.1837\n",
      "Seen so far: 9616 samples\n",
      "Training loss (for one batch) at step 800: 0.1306\n",
      "Seen so far: 12816 samples\n",
      "Training loss (for one batch) at step 1000: 0.0395\n",
      "Seen so far: 16016 samples\n",
      "Training loss (for one batch) at step 1200: 0.0543\n",
      "Seen so far: 19216 samples\n",
      "Training loss (for one batch) at step 1400: 0.0870\n",
      "Seen so far: 22416 samples\n",
      "Training loss (for one batch) at step 1600: 0.1517\n",
      "Seen so far: 25616 samples\n",
      "Training loss (for one batch) at step 1800: 0.0933\n",
      "Seen so far: 28816 samples\n",
      "Training loss (for one batch) at step 2000: 0.0357\n",
      "Seen so far: 32016 samples\n",
      "Training loss (for one batch) at step 2200: 0.0584\n",
      "Seen so far: 35216 samples\n",
      "Training loss (for one batch) at step 2400: 0.2595\n",
      "Seen so far: 38416 samples\n",
      "Training loss (for one batch) at step 2600: 0.1043\n",
      "Seen so far: 41616 samples\n",
      "Training loss (for one batch) at step 2800: 0.0586\n",
      "Seen so far: 44816 samples\n",
      "Training loss (for one batch) at step 3000: 0.0975\n",
      "Seen so far: 48016 samples\n",
      "Training acc over epoch: 0.9568\n",
      "Validation acc: 0.9824\n",
      "Time taken: 43.35s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 16 samples\n",
      "Training loss (for one batch) at step 200: 0.1611\n",
      "Seen so far: 3216 samples\n",
      "Training loss (for one batch) at step 400: 0.0019\n",
      "Seen so far: 6416 samples\n",
      "Training loss (for one batch) at step 600: 0.0266\n",
      "Seen so far: 9616 samples\n",
      "Training loss (for one batch) at step 800: 0.0186\n",
      "Seen so far: 12816 samples\n",
      "Training loss (for one batch) at step 1000: 0.0046\n",
      "Seen so far: 16016 samples\n",
      "Training loss (for one batch) at step 1200: 0.0226\n",
      "Seen so far: 19216 samples\n",
      "Training loss (for one batch) at step 1400: 0.0012\n",
      "Seen so far: 22416 samples\n",
      "Training loss (for one batch) at step 1600: 0.0474\n",
      "Seen so far: 25616 samples\n",
      "Training loss (for one batch) at step 1800: 0.0056\n",
      "Seen so far: 28816 samples\n",
      "Training loss (for one batch) at step 2000: 0.0089\n",
      "Seen so far: 32016 samples\n",
      "Training loss (for one batch) at step 2200: 0.0169\n",
      "Seen so far: 35216 samples\n",
      "Training loss (for one batch) at step 2400: 0.2655\n",
      "Seen so far: 38416 samples\n",
      "Training loss (for one batch) at step 2600: 0.0160\n",
      "Seen so far: 41616 samples\n",
      "Training loss (for one batch) at step 2800: 0.0074\n",
      "Seen so far: 44816 samples\n",
      "Training loss (for one batch) at step 3000: 0.0310\n",
      "Seen so far: 48016 samples\n",
      "Training acc over epoch: 0.9859\n",
      "Validation acc: 0.9875\n",
      "Time taken: 48.49s\n"
     ]
    }
   ],
   "source": [
    "# Training Script\n",
    "\n",
    "import time\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Reinstantiate datasets (don't have to do this for data generators or tf.data)\n",
    "    train_dataset = zip(train_images, train_labels)\n",
    "    val_dataset = zip(val_images, val_labels)\n",
    "    test_dataset = zip(test_images, test_labels)\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        \n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        \n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    \n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    \n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    \n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c1684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opence-v1.6.1]",
   "language": "python",
   "name": "conda-env-opence-v1.6.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
