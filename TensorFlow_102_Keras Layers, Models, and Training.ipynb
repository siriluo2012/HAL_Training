{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68765efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631884a",
   "metadata": {},
   "source": [
    "## 1. Defining Custom Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f911e83",
   "metadata": {},
   "source": [
    "The fundamental data structure in neural networks is the layer. A Layer is an object that encapsulates some state (weights) and some computation (a forward pass). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40400671",
   "metadata": {},
   "source": [
    "`tf.keras.layers.Layer` is the base class of all Keras layers, and it inherits from `tf.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ee931",
   "metadata": {},
   "source": [
    "#### a)  Define a Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2393cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    # Adding **kwargs to support base Keras layer arguments\n",
    "    def __init__(self, in_features, out_features, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.w = tf.Variable(\n",
    "          tf.random.normal([in_features, out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
    "    \n",
    "    def call(self, x):\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        return tf.nn.relu(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f51326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 14:32:23.732668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.6998929  0.24331883 0.         0.36765662]\n",
      " [2.8838756  0.         0.9268994  0.        ]\n",
      " [2.2448802  0.9250624  0.         1.3324821 ]\n",
      " [0.         1.2756517  0.         0.6899017 ]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your layer\n",
    "\n",
    "simple_layer = MyDense(name=\"simple\", in_features=2, out_features=4)\n",
    "\n",
    "\n",
    "# Call the layer on a sample input\n",
    "\n",
    "x = tf.random.normal((4,2))\n",
    "y = simple_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc483d54",
   "metadata": {},
   "source": [
    "#### b) Build Method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a64c5",
   "metadata": {},
   "source": [
    "It is often convenient to delay creating variables until the input shape is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac961342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([self.units]), name='b')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f73dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.6320368   1.3680271  -1.5001991  -0.03979062]\n",
      " [-1.4034127   1.7092023  -1.3292414  -0.04464768]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your layer\n",
    "\n",
    "flexible_layer = MyDense(name=\"simple\", units=4)\n",
    "\n",
    "\n",
    "# Call the layer on a sample input\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "y = flexible_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d806f781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple/w:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[ 0.9928404 , -1.1255851 ,  0.93421894,  0.02994949],\n",
       "        [-0.6392404 ,  0.26839444, -0.5679271 , -0.01034955]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple/b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this point we can inspect the variable\n",
    "\n",
    "flexible_layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11081e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple/b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also call the variables by name\n",
    "\n",
    "flexible_layer.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2ab5c",
   "metadata": {},
   "source": [
    "#### c) Non-trainable weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818c5d9",
   "metadata": {},
   "source": [
    "By default, the variables in a layer are trainable, i.e. they will tracked by the Gradient Tape and will be updated during backpropagation. However, we can also specify certain weights to be non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27f0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]), name='w', trainable=True)\n",
    "        self.b = tf.Variable(tf.zeros([self.units]), name='b', trainable=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6682423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the layer\n",
    "\n",
    "my_new_layer = MyDense(units=16)\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "y = my_new_layer(x)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ad08cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 2\n",
      "non-trainable weights: 1\n",
      "\n",
      " trainable_weights: [<tf.Variable 'my_dense/w:0' shape=(2, 16) dtype=float32, numpy=\n",
      "array([[ 0.90057856, -1.0036141 , -0.58286494,  1.1879911 , -0.36154723,\n",
      "         2.402001  ,  1.1370946 , -0.5823032 , -1.6684176 , -0.95081204,\n",
      "        -1.5145642 , -0.8617373 , -0.8604067 ,  1.1418787 , -0.52168334,\n",
      "         0.17226969],\n",
      "       [ 1.6129915 , -0.2245607 , -0.18759921,  0.3975187 , -0.06355886,\n",
      "         0.8081994 ,  0.59818935, -1.4164699 ,  1.6456181 , -0.06233479,\n",
      "         0.12785867, -0.11070318,  2.0580926 ,  1.5896587 , -1.7733927 ,\n",
      "         0.28407833]], dtype=float32)>]\n",
      "\n",
      " non trainable_weights: [<tf.Variable 'my_dense/b:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(\"weights:\", len(my_new_layer.weights))\n",
    "print(\"non-trainable weights:\", len(my_new_layer.non_trainable_weights))\n",
    "\n",
    "\n",
    "# It's not included in the trainable weights:\n",
    "print(\"\\n trainable_weights:\", my_new_layer.trainable_weights)\n",
    "print(\"\\n non trainable_weights:\", my_new_layer.non_trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8aeef",
   "metadata": {},
   "source": [
    "#### d) training arg in call()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "105bf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropout(tf.keras.layers.Layer):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(CustomDropout, self).__init__(**kwargs)\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate=self.rate)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e01b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tf.Tensor(\n",
      "[[ 1.0559696  -0.7131017 ]\n",
      " [ 0.77184045  1.237681  ]], shape=(2, 2), dtype=float32)\n",
      "\n",
      " output_during_training:  tf.Tensor(\n",
      "[[ 0.        -1.4262034]\n",
      " [ 1.5436809  2.475362 ]], shape=(2, 2), dtype=float32)\n",
      "\n",
      " output_during_inference:  tf.Tensor(\n",
      "[[ 1.0559696  -0.7131017 ]\n",
      " [ 0.77184045  1.237681  ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dropuout = CustomDropout(rate=0.5)\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "print('input: ', x)\n",
    "\n",
    "\n",
    "# During training\n",
    "output_during_training = dropuout(x, training=True)\n",
    "print('\\n output_during_training: ', output_during_training)\n",
    "\n",
    "\n",
    "# During inference\n",
    "output_during_inference = dropuout(x, training=False)\n",
    "print('\\n output_during_inference: ', output_during_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad32be",
   "metadata": {},
   "source": [
    "#### e) Recursively composible  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef3770",
   "metadata": {},
   "source": [
    "It also possible to compose a layer out of other layers. The outer layer will automatically track the weights of the inner layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3430e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 6\n",
      "trainable weights: 3\n",
      "y.shape:  (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Let's assume we are reusing the Linear class\n",
    "# with a `build` method that we defined above.\n",
    "\n",
    "\n",
    "class MLPBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.dense_1 = MyDense(32)\n",
    "        self.dense_2 = MyDense(32)\n",
    "        self.dense_3 = MyDense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return self.dense_3(x)\n",
    "\n",
    "\n",
    "mlp = MLPBlock()\n",
    "y = mlp(tf.ones(shape=(3, 64)))  # The first call to the `mlp` will create the weights\n",
    "print(\"weights:\", len(mlp.weights))\n",
    "print(\"trainable weights:\", len(mlp.trainable_weights))\n",
    "print(\"y.shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a134696",
   "metadata": {},
   "source": [
    "## 2. Defining Models: Three Levels of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb898c",
   "metadata": {},
   "source": [
    "Given a set of (either predefined or custom defined) layers, we can begin to start composing them into a DAG to define a model. A `tf.keras.Model` is similar to a `tf.keras.layers.Layer` except that models come with extra functionality that make them easy to train, evaluate, load, save, and even train on multiple machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e6f1f",
   "metadata": {},
   "source": [
    "#### a) Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b20252",
   "metadata": {},
   "source": [
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90892fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two ways to define a sequential model:\n",
    "\n",
    "# 1. Either as a list of layers\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(input_shape=(4,)),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(16),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Or instantiate a Sequential Model and add layers by calling the .add() method on it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.Dense(16))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "189310ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Now we can call the model on an Input Tensor\n",
    "x = tf.ones((16, 4))\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee53f0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 32)                160       \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can call summary method to display the graph\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609806d",
   "metadata": {},
   "source": [
    "#### b) Functional API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e28fe3",
   "metadata": {},
   "source": [
    "The __Functional API__ is more flexible than Sequential, and specifically come in handy when the model has non-linear topology, shared layers and/or multiple inputs, outputs.\n",
    "\n",
    "First, lets redefine the above model in Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a77a9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(4,))\n",
    "\n",
    "x = tf.keras.layers.Dense(32)(inputs)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Dense(16)(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"functional_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62392e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                160       \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 16)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f740b",
   "metadata": {},
   "source": [
    "With Functional API, it's easy to define more complex topologies. Lets define a model with multiple inputs and outputs.\n",
    "\n",
    "Let's say we want a model that takes in a few weather data variables on any given day to predict temperature and humidity for the same day:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "- Pressure\n",
    "- Precipitation\n",
    "- Clouds\n",
    "- Wind\n",
    "\n",
    "\n",
    "Outputs:\n",
    "\n",
    "- Temperature\n",
    "- Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd907233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets build this model\n",
    "\n",
    "pressure_input = tf.keras.layers.Input(shape=(1,), name='pressure')\n",
    "precipitation_input = tf.keras.layers.Input(shape=(1,), name='precipitation')\n",
    "clouds_input = tf.keras.layers.Input(shape=(1,), name='clouds')\n",
    "wind_input = tf.keras.layers.Input(shape=(1,), name='wind')\n",
    "\n",
    "\n",
    "# Lets pass the pressure and precipitaion through a one stack of linear layers, and clouds and wind through another\n",
    "x = tf.keras.layers.concatenate([pressure_input, precipitation_input])\n",
    "x = tf.keras.layers.Dense(units=32, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=16, activation='relu')(x)\n",
    "\n",
    "\n",
    "y = tf.keras.layers.concatenate([clouds_input, wind_input])\n",
    "y = tf.keras.layers.Dense(units=32, activation='relu')(y)\n",
    "y = tf.keras.layers.Dense(units=16, activation='relu')(y)\n",
    "\n",
    "\n",
    "# Lets merge the two branches and send through a few more layers\n",
    "z = tf.keras.layers.concatenate([x,y])\n",
    "z = tf.keras.layers.Dense(units=32, activation='relu')(z)\n",
    "z = tf.keras.layers.Dense(units=16, activation='relu')(z)\n",
    "\n",
    "# Finally split again into two outputs\n",
    "temperature = tf.keras.layers.Dense(units=1, name='temperature')(z)\n",
    "humidity = tf.keras.layers.Dense(units=1, name='humidity')(z)\n",
    "\n",
    "\n",
    "multiple_inp_model = tf.keras.Model(inputs=[pressure_input, precipitation_input, clouds_input, wind_input], \n",
    "                       outputs=[temperature, humidity], name=\"multi_input_output_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eeaa794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi_input_output_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " pressure (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " precipitation (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " clouds (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " wind (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2)            0           ['pressure[0][0]',               \n",
      "                                                                  'precipitation[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2)            0           ['clouds[0][0]',                 \n",
      "                                                                  'wind[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 32)           96          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 32)           96          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 16)           528         ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 16)           528         ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32)           0           ['dense_10[0][0]',               \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 32)           1056        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 16)           528         ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " temperature (Dense)            (None, 1)            17          ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " humidity (Dense)               (None, 1)            17          ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,866\n",
      "Trainable params: 2,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can print the summary but it might be difficult to visualize the graph\n",
    "multiple_inp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deb92d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# Luckily we can also plot the model\n",
    "tf.keras.utils.plot_model(multiple_inp_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d1a9b",
   "metadata": {},
   "source": [
    "#### c) Subclassing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c91f948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FCN, self).__init__()\n",
    "        self.dense_1 = tf.keras.layers.Dense(32)\n",
    "        self.dense_2 = tf.keras.layers.Dense(16)\n",
    "        self.dense_3 = tf.keras.layers.Dense(1)\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.dense_3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f460f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "model = FCN()\n",
    "\n",
    "\n",
    "# Call the model on an Input Tensor\n",
    "x = tf.ones((16, 4))\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcd8cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fcn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            multiple                  160       \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  528       \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  17        \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d251e92",
   "metadata": {},
   "source": [
    "## 3. Training: Three Levels of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59662669",
   "metadata": {},
   "source": [
    "For this exercise, we will fix the model architecture (a small CNN) and train it on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3068e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "train_images, val_images = train_images[:50000], train_images[50000:]\n",
    "train_labels, val_labels = train_labels[:50000], train_labels[50000:]\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "val_labels = to_categorical(val_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b01d2911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "Input = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(Input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "Output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "my_CNN = tf.keras.Model(inputs=Input, outputs=Output)\n",
    "my_CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04d592",
   "metadata": {},
   "source": [
    "#### a) Model.fit() method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4528e",
   "metadata": {},
   "source": [
    "To use the built in methods `(Model.fit(), Model.evaluate(), Model.predict() `, we simply need to specify the\n",
    "- optimizer\n",
    "- loss\n",
    "- metrics\n",
    "\n",
    "and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56b655a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_CNN.compile(\n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    # Loss function to minimize\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a0938",
   "metadata": {},
   "source": [
    "The `.fit()` method will accept `numpy arrays`, `tf.data.Dataset` objects and `data generators`. Here we will input the MNIST data as a numpy array.\n",
    "\n",
    "The `.fit()` method can slice the data into batches, and will iterate over the entire dataset for a given number of epochs. Additionally, after each epoch it will evaluate on a hold-out validation set if specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f91d4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 14:33:19.863515: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 149.54MiB (rounded to 156800000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-09-19 14:33:19.863571: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-09-19 14:33:19.863585: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 74, Chunks in use: 74. 18.5KiB allocated for chunks. 18.5KiB in use in bin. 3.8KiB client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863595: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 3, Chunks in use: 3. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 1.5KiB client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863604: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.1KiB client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863613: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 9, Chunks in use: 7. 21.0KiB allocated for chunks. 16.0KiB in use in bin. 14.5KiB client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863622: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 2, Chunks in use: 2. 8.0KiB allocated for chunks. 8.0KiB in use in bin. 8.0KiB client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863630: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 1, Chunks in use: 1. 8.0KiB allocated for chunks. 8.0KiB in use in bin. 8.0KiB client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863639: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863647: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863655: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 1, Chunks in use: 1. 72.0KiB allocated for chunks. 72.0KiB in use in bin. 72.0KiB client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863664: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 4, Chunks in use: 2. 571.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863672: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863680: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863687: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863695: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863703: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 0. 7.06MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863710: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863718: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863725: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863733: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863740: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863748: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-09-19 14:33:19.863757: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 149.54MiB was 128.00MiB, Chunk State: \n",
      "2022-09-19 14:33:19.863763: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 8126464\n",
      "2022-09-19 14:33:19.863774: I tensorflow/core/common_runtime/bfc_allocato"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1256110/2264919876.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = my_CNN.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/opence-v1.6.1/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/opence-v1.6.1/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r.cc:1066] InUse at 7ffe3ba00000 of size 1280 next 1\n",
      "2022-09-19 14:33:19.863781: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00500 of size 256 next 2\n",
      "2022-09-19 14:33:19.863790: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00600 of size 256 next 3\n",
      "2022-09-19 14:33:19.863796: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00700 of size 256 next 4\n",
      "2022-09-19 14:33:19.863803: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00800 of size 256 next 5\n",
      "2022-09-19 14:33:19.863810: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00900 of size 256 next 6\n",
      "2022-09-19 14:33:19.863817: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00a00 of size 256 next 7\n",
      "2022-09-19 14:33:19.863823: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00b00 of size 256 next 8\n",
      "2022-09-19 14:33:19.863830: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00c00 of size 256 next 9\n",
      "2022-09-19 14:33:19.863837: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00d00 of size 256 next 10\n",
      "2022-09-19 14:33:19.863843: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00e00 of size 256 next 11\n",
      "2022-09-19 14:33:19.863850: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba00f00 of size 256 next 17\n",
      "2022-09-19 14:33:19.863857: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba01000 of size 256 next 13\n",
      "2022-09-19 14:33:19.863863: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba01100 of size 256 next 14\n",
      "2022-09-19 14:33:19.863870: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba01200 of size 256 next 15\n",
      "2022-09-19 14:33:19.863876: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba01300 of size 256 next 16\n",
      "2022-09-19 14:33:19.863883: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba01400 of size 256 next 12\n",
      "2022-09-19 14:33:19.863889: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba01500 of size 256 next 18\n",
      "2022-09-19 14:33:19.863896: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba01600 of size 256 next 19\n",
      "2022-09-19 14:33:19.863903: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba01700 of size 512 next 48\n",
      "2022-09-19 14:33:19.863910: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba01900 of size 3584 next 35\n",
      "2022-09-19 14:33:19.863917: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba02700 of size 2048 next 34\n",
      "2022-09-19 14:33:19.863924: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba02f00 of size 256 next 39\n",
      "2022-09-19 14:33:19.863931: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03000 of size 256 next 44\n",
      "2022-09-19 14:33:19.863937: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03100 of size 256 next 40\n",
      "2022-09-19 14:33:19.863944: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03200 of size 256 next 42\n",
      "2022-09-19 14:33:19.863951: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03300 of size 256 next 41\n",
      "2022-09-19 14:33:19.863957: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03400 of size 256 next 45\n",
      "2022-09-19 14:33:19.863964: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03500 of size 256 next 47\n",
      "2022-09-19 14:33:19.863970: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03600 of size 256 next 50\n",
      "2022-09-19 14:33:19.863977: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03700 of size 256 next 51\n",
      "2022-09-19 14:33:19.863983: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03800 of size 256 next 52\n",
      "2022-09-19 14:33:19.863990: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03900 of size 256 next 23\n",
      "2022-09-19 14:33:19.863997: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba03a00 of size 4096 next 24\n",
      "2022-09-19 14:33:19.864004: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba04a00 of size 256 next 20\n",
      "2022-09-19 14:33:19.864010: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba04b00 of size 256 next 25\n",
      "2022-09-19 14:33:19.864017: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba04c00 of size 256 next 26\n",
      "2022-09-19 14:33:19.864023: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba04d00 of size 256 next 27\n",
      "2022-09-19 14:33:19.864030: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba04e00 of size 256 next 28\n",
      "2022-09-19 14:33:19.864036: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba04f00 of size 256 next 29\n",
      "2022-09-19 14:33:19.864043: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba05000 of size 256 next 32\n",
      "2022-09-19 14:33:19.864050: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba05100 of size 256 next 33\n",
      "2022-09-19 14:33:19.864056: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba05200 of size 256 next 30\n",
      "2022-09-19 14:33:19.864063: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba05300 of size 512 next 31\n",
      "2022-09-19 14:33:19.864069: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba05500 of size 256 next 36\n",
      "2022-09-19 14:33:19.864076: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba05600 of size 256 next 37\n",
      "2022-09-19 14:33:19.864083: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba05700 of size 256 next 38\n",
      "2022-09-19 14:33:19.864089: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba05800 of size 256 next 62\n",
      "2022-09-19 14:33:19.864096: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba05900 of size 256 next 21\n",
      "2022-09-19 14:33:19.864103: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba05a00 of size 8192 next 22\n",
      "2022-09-19 14:33:19.864109: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba07a00 of size 256 next 74\n",
      "2022-09-19 14:33:19.864116: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba07b00 of size 256 next 76\n",
      "2022-09-19 14:33:19.864123: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba07c00 of size 256 next 77\n",
      "2022-09-19 14:33:19.864129: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba07d00 of size 256 next 67\n",
      "2022-09-19 14:33:19.864136: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba07e00 of size 512 next 68\n",
      "2022-09-19 14:33:19.864142: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08000 of size 256 next 66\n",
      "2022-09-19 14:33:19.864149: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08100 of size 256 next 43\n",
      "2022-09-19 14:33:19.864156: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08200 of size 256 next 53\n",
      "2022-09-19 14:33:19.864162: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08300 of size 256 next 56\n",
      "2022-09-19 14:33:19.864169: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08400 of size 256 next 57\n",
      "2022-09-19 14:33:19.864175: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08500 of size 256 next 59\n",
      "2022-09-19 14:33:19.864182: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08600 of size 256 next 63\n",
      "2022-09-19 14:33:19.864188: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08700 of size 256 next 64\n",
      "2022-09-19 14:33:19.864195: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08800 of size 256 next 65\n",
      "2022-09-19 14:33:19.864202: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08900 of size 256 next 46\n",
      "2022-09-19 14:33:19.864208: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba08a00 of size 2048 next 49\n",
      "2022-09-19 14:33:19.864215: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba09200 of size 256 next 71\n",
      "2022-09-19 14:33:19.864221: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba09300 of size 256 next 72\n",
      "2022-09-19 14:33:19.864228: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba09400 of size 256 next 73\n",
      "2022-09-19 14:33:19.864235: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba09500 of size 256 next 78\n",
      "2022-09-19 14:33:19.864241: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba09600 of size 256 next 81\n",
      "2022-09-19 14:33:19.864248: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba09700 of size 256 next 84\n",
      "2022-09-19 14:33:19.864254: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba09800 of size 256 next 85\n",
      "2022-09-19 14:33:19.864261: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba09900 of size 256 next 55\n",
      "2022-09-19 14:33:19.864267: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba09a00 of size 2048 next 54\n",
      "2022-09-19 14:33:19.864274: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0a200 of size 2048 next 58\n",
      "2022-09-19 14:33:19.864281: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0aa00 of size 1280 next 75\n",
      "2022-09-19 14:33:19.864287: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ffe3ba0af00 of size 2816 next 70\n",
      "2022-09-19 14:33:19.864294: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0ba00 of size 2048 next 69\n",
      "2022-09-19 14:33:19.864301: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0c200 of size 256 next 87\n",
      "2022-09-19 14:33:19.864307: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0c300 of size 256 next 88\n",
      "2022-09-19 14:33:19.864314: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0c400 of size 256 next 89\n",
      "2022-09-19 14:33:19.864320: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0c500 of size 256 next 92\n",
      "2022-09-19 14:33:19.864327: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0c600 of size 256 next 93\n",
      "2022-09-19 14:33:19.864333: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0c700 of size 256 next 94\n",
      "2022-09-19 14:33:19.864340: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0c800 of size 256 next 95\n",
      "2022-09-19 14:33:19.864347: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0c900 of size 256 next 61\n",
      "2022-09-19 14:33:19.864353: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0ca00 of size 4096 next 60\n",
      "2022-09-19 14:33:19.864360: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0da00 of size 256 next 96\n",
      "2022-09-19 14:33:19.864367: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ffe3ba0db00 of size 2304 next 91\n",
      "2022-09-19 14:33:19.864373: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba0e400 of size 2560 next 90\n",
      "2022-09-19 14:33:19.864380: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ffe3ba0ee00 of size 142336 next 79\n",
      "2022-09-19 14:33:19.864387: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba31a00 of size 73728 next 80\n",
      "2022-09-19 14:33:19.864394: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ffe3ba43a00 of size 147456 next 83\n",
      "2022-09-19 14:33:19.864401: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba67a00 of size 147456 next 82\n",
      "2022-09-19 14:33:19.864408: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ffe3ba8ba00 of size 147456 next 86\n",
      "2022-09-19 14:33:19.864415: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ffe3baafa00 of size 7407104 next 18446744073709551615\n",
      "2022-09-19 14:33:19.864421: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-09-19 14:33:19.864430: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 74 Chunks of size 256 totalling 18.5KiB\n",
      "2022-09-19 14:33:19.864437: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 512 totalling 1.5KiB\n",
      "2022-09-19 14:33:19.864444: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2022-09-19 14:33:19.864452: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 5 Chunks of size 2048 totalling 10.0KiB\n",
      "2022-09-19 14:33:19.864459: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2560 totalling 2.5KiB\n",
      "2022-09-19 14:33:19.864466: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 3584 totalling 3.5KiB\n",
      "2022-09-19 14:33:19.864473: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 4096 totalling 8.0KiB\n",
      "2022-09-19 14:33:19.864480: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 8192 totalling 8.0KiB\n",
      "2022-09-19 14:33:19.864488: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 73728 totalling 72.0KiB\n",
      "2022-09-19 14:33:19.864495: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 147456 totalling 288.0KiB\n",
      "2022-09-19 14:33:19.864502: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 414.5KiB\n",
      "2022-09-19 14:33:19.864509: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 8126464 memory_limit_: 8126464 available bytes: 0 curr_region_allocation_bytes_: 16252928\n",
      "2022-09-19 14:33:19.864519: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                         8126464\n",
      "InUse:                          424448\n",
      "MaxInUse:                       714496\n",
      "NumAllocs:                         233\n",
      "MaxAllocSize:                   147456\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-09-19 14:33:19.864529: W tensorflow/core/common_runtime/bfc_allocator.cc:474] *_**_****___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = my_CNN.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    validation_data=(val_images, val_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd1e6b",
   "metadata": {},
   "source": [
    "The returned history object holds a record of the loss and metric values recorded at the end of each epoch during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ed3a4ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1256110/1223029480.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7bac2",
   "metadata": {},
   "source": [
    "After training, we can call the `evaaluate` or `predict` methods on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_CNN.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = my_CNN.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324636e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa68b6e",
   "metadata": {},
   "source": [
    "###### What if there are multiple outputs? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2529838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple_inp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd13da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_inp_model.compile(\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    \n",
    "    # Loss function to minimize\n",
    "    loss = {\n",
    "        'temperature': tf.keras.losses.MeanSquaredError(),\n",
    "        'humidity': tf.keras.losses.CategoricalCrossentropy()\n",
    "    },\n",
    "    \n",
    "    # List of metrics to monitor\n",
    "    metrics = {\n",
    "        'temperature': [tf.keras.metrics.MeanAbsoluteError(),],\n",
    "        'humidity': [tf.keras.metrics.CategoricalAccuracy(),]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07378b",
   "metadata": {},
   "source": [
    "#### b) Customizing what happens in Model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a8101",
   "metadata": {},
   "source": [
    "To customize what `fit()` does, we just need to override the `train_step(self, data)` method of the `Model` class.\n",
    "\n",
    "Let's do this with our simple CNN from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9159f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
    "\n",
    "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "accuracy_tracker = tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "\n",
    "\n",
    "class CustomModel(tf.keras.Model):\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute our own loss\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, y_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Compute our own metrics\n",
    "        loss_tracker.update_state(loss)\n",
    "        accuracy_tracker.update_state(y, y_pred)\n",
    "        return {\"loss\": loss_tracker.result(), \"acc\": accuracy_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [loss_tracker, accuracy_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd77ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture\n",
    "Input = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(Input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "Output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reconstruct an instance of our CNN model\n",
    "my_new_CNN = CustomModel(inputs=Input, outputs=Output)\n",
    "\n",
    "# Now during compilation we don't need to pass loss or metrics\n",
    "my_new_CNN.compile(optimizer=\"adam\")\n",
    "\n",
    "# Print summary\n",
    "my_new_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a871b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train \n",
    "my_new_CNN.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size=64,\n",
    "    epochs=2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996535a0",
   "metadata": {},
   "source": [
    "#### c) Training Loop from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "\n",
    "Input = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(Input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "Output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=Input, outputs=Output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be387ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to simulate batches\n",
    "\n",
    "batch_size= 16\n",
    "\n",
    "train_images = train_images.reshape(-1, batch_size, 28,28,1)\n",
    "val_images = val_images.reshape(-1, batch_size, 28,28,1)\n",
    "test_images = test_images.reshape(-1, batch_size, 28,28,1)\n",
    "\n",
    "train_labels = train_labels.reshape(-1, batch_size, 10)\n",
    "val_labels = val_labels.reshape(-1, batch_size, 10)\n",
    "test_labels = test_labels.reshape(-1, batch_size, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92019d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer, Loss functions and Metrics\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "# Prepare the metrics.\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c15833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Script\n",
    "\n",
    "import time\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Reinstantiate datasets (don't have to do this for data generators or tf.data)\n",
    "    train_dataset = zip(train_images, train_labels)\n",
    "    val_dataset = zip(val_images, val_labels)\n",
    "    test_dataset = zip(test_images, test_labels)\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        \n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        \n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    \n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    \n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    \n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c1684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opence-v1.6.1]",
   "language": "python",
   "name": "conda-env-opence-v1.6.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
